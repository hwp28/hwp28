{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "딥러닝_종사자예측.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hwp28/hwp28/blob/main/%EB%94%A5%EB%9F%AC%EB%8B%9D_%EC%A2%85%EC%82%AC%EC%9E%90%EC%98%88%EC%B8%A1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFgustPaUSS1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c33a4bd4-2a17-4277-d5ae-289d41a9f3cc"
      },
      "source": [
        "# 라이브러리 import \n",
        "# 패키지 및 라이브러리 import\n",
        "import pandas as pd                       # dataframe\n",
        "import numpy as np                        # array등 수치데이터 처리 \n",
        "import matplotlib.pyplot as plt           # 그래프 \n",
        "\n",
        "# 머신러닝 라이브러리 \n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 딥러닝 라이브러리 \n",
        "from keras.utils import plot_model        # keras 모델 이미지 \n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Input\n",
        "\n",
        "# keras \n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import LSTM\n",
        "\n",
        "# 구글 드라이브 마운트 ( 자원 접근 권한 관련 )\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWgJY6mDVEe7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "917ac6ee-cd60-4521-ee12-6dcbc8b2d56b"
      },
      "source": [
        "# 학습용 전체 데이터 import \n",
        "df = pd.read_csv('/content/drive/My Drive/project/2013_2019_분기별 종사자수.csv')\n",
        "df.head()\n",
        "df.columns"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['REG_DT', 'DIVIDE', 'Care practician', 'Electron practician ', 'TOTAL'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KUaafPSVonU"
      },
      "source": [
        "# 전처리\n",
        "# 전체 데이터(df_total: 전체종업자수)와 세부 데이터(df_care:보건) /(df_electron:전기운수업) 를 나눠서 학습 \n",
        "df_total = df[['REG_DT','DIVIDE','TOTAL']]                        # 전체 취업자\n",
        "df_care  = df[['REG_DT','DIVIDE','Care practician']]              # 보건업체 종사자\n",
        "df_electron = df[['REG_DT','DIVIDE','Electron practician ']]      # 전기운수업 종사자\n",
        "# df_electron = \n",
        "df_care = df_care.rename(columns={'Care practician':'CP'})                            # 컬럼명 길어서 변경 "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpR-4mgpgGD6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e48f6e63-748a-4869-cc32-ca330caa9f3d"
      },
      "source": [
        "df_electron.rename(columns={'Electron practician ':'EP'},inplace=True)  # 컬럼명 길어서 변경 "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4308: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpUKnK2CgM8z"
      },
      "source": [
        "df_electron"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNIPHqnJa6lV"
      },
      "source": [
        "df_total = df_total.drop(['DIVIDE'], axis=1)\n",
        "df_total"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_8CcxCDYfLR"
      },
      "source": [
        "##############################################################################\n",
        "# 함수 time split ( 연(year) 단위로 데이터 묶음)\n",
        "##############################################################################\n",
        "def split_xy(dataset, time_steps, y_column):\n",
        "    x, y = list(), list()\n",
        "    for i in range(len(dataset)):\n",
        "        x_end_number = i + time_steps\n",
        "        y_end_number = x_end_number + y_column # 수정\n",
        "\n",
        "        if y_end_number > len(dataset):  # 수정\n",
        "            break\n",
        "        tmp_x = dataset[i:x_end_number, :]  # 수정\n",
        "        tmp_y = dataset[x_end_number:y_end_number, 1]    # 수정\n",
        "        x.append(tmp_x)\n",
        "        y.append(tmp_y)\n",
        "    return np.array(x), np.array(y)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cScqQAReaRAe"
      },
      "source": [
        "x1, y1 = split_xy(df_total.values, 4, 1) # 4분기(1년치 데이터를 기준으로) 다음 1분기를 예측한다."
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTN3qnN4R2CW"
      },
      "source": [
        "x1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5hC-YdKSLde"
      },
      "source": [
        "# 보건업 종사자 관련 데이터 Standard Scaling \n",
        "x2 = df_care[df_care['REG_DT'] >= 2014]\n",
        "x2 = x2.drop(['REG_DT'], axis=1)\n",
        "# df_care 데이터 전처리 \n",
        "from sklearn.model_selection import train_test_split\n",
        "x2_train, x2_test = train_test_split(x2, random_state=1,  test_size = 0.3)\n",
        "\n",
        "#### 데이터 Scaling #####\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(x2_train)\n",
        "x2_train_scaled = scaler.transform(x2_train)\n",
        "x2_test_scaled = scaler.transform(x2_test)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6cqiXgha22n"
      },
      "source": [
        "# 데이터 전처리 \n",
        "from sklearn.model_selection import train_test_split\n",
        "x1_train, x1_test, y1_train, y1_test = train_test_split(x1, y1, random_state=1,  test_size = 0.3)\n",
        "\n",
        "# Standard Scaling 하기 위해 2차원 배열로 변경\n",
        "x1_train = np.reshape(x1_train, (x1_train.shape[0], x1_train.shape[1] * x1_train.shape[2])) \n",
        "x1_test = np.reshape(x1_test, (x1_test.shape[0], x1_test.shape[1] * x1_test.shape[2]))\n",
        "\n",
        "# #### 데이터 Scaling #####\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler1 = StandardScaler()\n",
        "scaler1.fit(x1_train)\n",
        "x1_train_scaled = scaler1.transform(x1_train)\n",
        "x1_test_scaled = scaler1.transform(x1_test)\n",
        "x1_train_scaled = np.reshape(x1_train_scaled, (x1_train_scaled.shape[0], 4, 2))\n",
        "x1_test_scaled = np.reshape(x1_test_scaled, (x1_test_scaled.shape[0], 4, 2)) # 7일 단위 3개 feature 데이터를 저장 "
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDrRpIp9lmZB"
      },
      "source": [
        "# 데이터 전처리 \n",
        "from sklearn.model_selection import train_test_split\n",
        "x1_train, x1_test, y1_train, y1_test = train_test_split(x1, y1, random_state=1,  test_size = 0.3)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Th6jpVJzdO3R"
      },
      "source": [
        "# 모델 생성 및 학습 ( PV, RLORD_AMT 에 대한 lstm )\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Input, LSTM\n",
        "\n",
        "study_size = 4 # 1년(4분기)\n",
        "feature_size = 1 # 년도별 취업자수 feature 보겠다는 의미 \n",
        "\n",
        "input1 = Input(shape=(study_size, 2))\n",
        "dense1 = LSTM(64)(input1)\n",
        "dense1 = Dense(32)(dense1)\n",
        "dense1 = Dense(32)(dense1)\n",
        "output1 = Dense(1)(dense1)\n",
        "model1 = Model(inputs=[input1], outputs = output1)\n",
        "\n",
        "\n",
        "# model1 = models.model_create_timeseries_for_concatenate(7, 3) # 7일단위 ( memory cell ) 2개 feature 데이터를 저장 \n",
        "model1.compile(loss='mae', optimizer='adam')\n",
        "model1.fit([x1_train_scaled], y1_train, validation_split=0.2, verbose=1, batch_size=2000, epochs=500)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vl4Ly45beC9I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f54be800-92c8-4aee-8bfc-c1d9accccec3"
      },
      "source": [
        "# y1_pred = lstm 모델 (PV, RLORD_AMT, ORD_CNT) 로 예측한 RLORD_AMT \n",
        "loss = model1.evaluate([x1_train_scaled], y1_train, batch_size=1)\n",
        "print('loss : ', loss)\n",
        "\n",
        "y1_pred = model1.predict([x1_train_scaled])\n",
        "print('<<<<<<<<<<model 1 예측>>>>>>>>>>')\n",
        "for i in range(5):    \n",
        "    print('(실제) : ', y1_test[i], '/ (예측) : ', y1_pred[i], '정확도(%) : ', y1_pred[i] / y1_test[i] * 100, '오차 : ',np.absolute(y1_test[i]-y1_pred[i]).astype(int))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "19/19 [==============================] - 0s 2ms/step - loss: 341.5583\n",
            "loss :  341.55828857421875\n",
            "<<<<<<<<<<model 1 예측>>>>>>>>>>\n",
            "(실제) :  [26749] / (예측) :  [26333.023] 정확도(%) :  [98.44488929] 오차 :  [415]\n",
            "(실제) :  [27019] / (예측) :  [26132.896] 정확도(%) :  [96.72044296] 오차 :  [886]\n",
            "(실제) :  [26971] / (예측) :  [26757.277] 정확도(%) :  [99.20758349] 오차 :  [213]\n",
            "(실제) :  [26461] / (예측) :  [26589.457] 정확도(%) :  [100.48545796] 오차 :  [128]\n",
            "(실제) :  [26998] / (예측) :  [26751.602] 정확도(%) :  [99.08734559] 오차 :  [246]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJDrXzAjejqY"
      },
      "source": [
        "# y1_pred 실제값과 비교한 그래프 \n",
        "%matplotlib inline\n",
        "import matplotlib.pylab as plt\n",
        "plt.rcParams[\"figure.figsize\"] = (14,10)\n",
        "plt.rcParams['lines.linewidth'] = 2\n",
        "plt.rcParams['lines.color'] = 'r'\n",
        "plt.rcParams['axes.grid'] = True \n",
        "\n",
        "plt.plot(y1_train)\n",
        "plt.plot(y1_pred)\n",
        "plt.title('single model predict')\n",
        "plt.legend(['real', 'test'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwXi8tSgelM3"
      },
      "source": [
        "# 비선형 학습 세트 추가 \n",
        "df_care = df_care.drop(['DIVIDE'], axis=1)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGj--ohpgsqm"
      },
      "source": [
        "# non linear model modeling \n",
        "dim = 2 # 입력 feature가 1개니까 \n",
        "model2 = keras.Sequential()\n",
        "model2.add(layers.Dense(10, input_dim=dim, activation='relu'))\n",
        "model2.add(layers.Dense(5, activation='relu'))\n",
        "model2.add(layers.Dense(1))  \n",
        "model2.add(layers.Activation('relu'))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9u7gcUQ6g8Zm"
      },
      "source": [
        "# Keras Concatenate \n",
        "from tensorflow.keras.layers import concatenate\n",
        "combinedInput = concatenate([model1.output, model2.output])\n",
        "x = Dense(10, activation=\"relu\")(combinedInput)\n",
        "x = Dense(10, activation=\"relu\")(x)\n",
        "model_merged = Model(inputs=[model1.input, model2.input], outputs=x)\n",
        "plot_model(model_merged, to_file='model_merged.png', show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pj1j-lLI2mzU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7922b87e-e68a-41ff-c1dd-985ef5052b7d"
      },
      "source": [
        "print(x1_train_scaled.shape)\n",
        "print(x2_train_scaled.shape)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(19, 4, 2)\n",
            "(19, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0E77Wvjhofe"
      },
      "source": [
        "# fitting \n",
        "from tensorflow import keras\n",
        "opt = keras.optimizers.Adam(learning_rate=0.1)\n",
        "model_merged.compile(loss=\"mae\", optimizer=opt)\n",
        "hist = model_merged.fit(\t\n",
        "  [x1_train_scaled, x2_train_scaled], y1_train,  \n",
        "  validation_split=0.2, \t\n",
        " \tepochs=500,\tbatch_size=800)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqciSyj7T1yR"
      },
      "source": [
        "loss = model_merged.evaluate([x1_train_scaled, x2_train_scaled], y1_train, batch_size=1)\n",
        "print('loss : ', loss)\n",
        "y_pred = model_merged.predict([x1_train_scaled, x2_train_scaled])\n",
        "print('<<<<<<<<<<merged model 예측>>>>>>>>>>')\n",
        "for i in range(10):    \n",
        "    print('(실제) : ', y1_train[i])\n",
        "    print('(예측) : ', y1_pred[i].astype(int)) \n",
        "    print('오차           : ', np.absolute(y1_train[i] - y1_pred[i]).astype(int))    \n",
        "    print('오차율(%)      : ', abs(y1_train[i]-y1_pred[i]) / y1_pred[i]*100)\n",
        "    print()          "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YjaVRNKh9d3"
      },
      "source": [
        "# 1. LSTM + Non-linear(relu) 구성시 정확도 그래프 \n",
        "plt.plot(y1_train, color='r')\n",
        "plt.plot(y1_pred)\n",
        "plt.legend(['real'], prop={'size': 22}, bbox_to_anchor=(0.99, 1.02))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rF91hPL1iGBw"
      },
      "source": [
        "# 2. LSTM + LSTM 구성시 정확도 \n",
        "# x1, y1은 그대로 \n",
        "# x2, y2는 lstm \n",
        "x2, y2 = split_xy(df_care.values, 4, 1) # 4분기(1년치 데이터를 기준으로) 다음 1분기를 예측한다.\n",
        "\n",
        "# 데이터 전처리 \n",
        "from sklearn.model_selection import train_test_split\n",
        "x2_train, x2_test, y2_train, y2_test = train_test_split(x2, y2, random_state=1,  test_size = 0.3)\n",
        "\n",
        "# Standard Scaling 하기 위해 2차원 배열로 변경\n",
        "x2_train = np.reshape(x2_train, (x2_train.shape[0], x2_train.shape[1] * x2_train.shape[2])) \n",
        "x2_test = np.reshape(x2_test, (x2_test.shape[0], x2_test.shape[1] * x2_test.shape[2]))\n",
        "\n",
        "# #### 데이터 Scaling #####\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler1 = StandardScaler()\n",
        "scaler1.fit(x2_train)\n",
        "x2_train_scaled = scaler1.transform(x2_train)\n",
        "x2_test_scaled = scaler1.transform(x2_test)\n",
        "x2_train_scaled = np.reshape(x2_train_scaled, (x2_train_scaled.shape[0], 4, 2))\n",
        "x2_test_scaled = np.reshape(x2_test_scaled, (x2_test_scaled.shape[0], 4, 2)) # 7일 단위 3개 feature 데이터를 저장 "
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1V_BcPhW8sK"
      },
      "source": [
        "# model2 remodeling ( model2는 nonlinear 였기 때문에 lstm으로 재구성)\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Input, LSTM\n",
        "\n",
        "study_size = 4   # 1년(4분기)\n",
        "feature_size = 1 # 년도별 취업자수 feature 보겠다는 의미 \n",
        "\n",
        "input2 = Input(shape=(study_size, 2))\n",
        "dense2 = LSTM(64)(input2)\n",
        "dense2 = Dense(32)(dense2)\n",
        "dense2 = Dense(32)(dense2)\n",
        "output2 = Dense(1)(dense2)\n",
        "model2 = Model(inputs=[input2], outputs = output2)\n",
        "\n",
        "# Keras Concatenate \n",
        "from tensorflow.keras.layers import concatenate\n",
        "combinedInput = concatenate([model1.output, model2.output])\n",
        "x = Dense(10, activation=\"relu\")(combinedInput)\n",
        "x = Dense(10, activation=\"relu\")(x)\n",
        "model_merged = Model(inputs=[model1.input, model2.input], outputs=x)\n",
        "plot_model(model_merged, to_file='model_merged.png', show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1HE3yBSWaKj"
      },
      "source": [
        "# fitting \n",
        "from tensorflow import keras\n",
        "opt = keras.optimizers.Adam(learning_rate=0.1)\n",
        "model_merged.compile(loss=\"mae\", optimizer=opt)\n",
        "\n",
        "hist = model_merged.fit(\t\n",
        "  [x1_train_scaled, x2_train_scaled], y2_train,  \n",
        "  validation_split=0.2, \t\n",
        " \tepochs=500,\tbatch_size=800)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SQJyeclW7Py"
      },
      "source": [
        "loss = model_merged.evaluate([x1_train_scaled, x2_train_scaled], y2_train, batch_size=1)\n",
        "print('loss : ', loss)\n",
        "y2_pred = model_merged.predict([x1_train_scaled, x2_train_scaled])\n",
        "print('<<<<<<<<<<merged model 예측>>>>>>>>>>')\n",
        "for i in range(10):    \n",
        "    print('(실제) : ', y2_train[i])\n",
        "    print('(예측) : ', y2_pred[i].astype(int))     \n",
        "    print('오차           : ', np.absolute(y2_train[i] - y2_pred[i]).astype(int))    \n",
        "    print('정확도(%)      : ', y2_pred[i] / y2_train[i] * 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tksSlPTvYiOY"
      },
      "source": [
        "# np.delete(y2_pred, np.where(y2_pred.astype(int)==0.0))\n",
        "index = np.where(y2_pred == 0.).index"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Jxv4llrYIoY"
      },
      "source": [
        "# 1. LSTM + Non-linear(relu) 구성시 정확도 그래프 \n",
        "plt.plot(y2_train, color='r')\n",
        "plt.plot(y2_pred)\n",
        "plt.ylim(2800, 3400)\n",
        "plt.legend(['real'], prop={'size': 22}, bbox_to_anchor=(0.99, 1.02))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWYQ-gs1YMPX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}